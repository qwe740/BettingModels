{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93adb4f",
   "metadata": {},
   "source": [
    "# College Football Spread Betting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb352c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0974a90a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.errors' has no attribute 'SettingWithCopyWarning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopponent_adjustments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_opponent_adjustments\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error, r2_score\n",
      "File \u001b[1;32mc:\\Users\\austi\\Documents\\Local Docs\\github\\BettingModels\\opponent_adjustments.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Warnings\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSettingWithCopyWarning\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Config\u001b[39;00m\n\u001b[0;32m     11\u001b[0m DB_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfb_data.db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas.errors' has no attribute 'SettingWithCopyWarning'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from opponent_adjustments import get_opponent_adjustments\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import Model_Functions as MF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378591c2",
   "metadata": {},
   "source": [
    "## Config Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daeb9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config - Major Inputs\n",
    "DB_PATH = \"cfb_data.db\"\n",
    "PRE_GAME_ELO_CSV_PATH = 'games_with_pregame_elo.csv'\n",
    "#Define RP metrics to load and use\n",
    "RP_METRICS_TO_USE =['usage','percentPPA']\n",
    "# Define dfault value for missing RP data (e.g., average)\n",
    "DEFAULT_RP_VALUE = 0.5\n",
    "# Define how many weeks RP features should be active\n",
    "RP_ACTIVE_WEEKS = 4\n",
    "#Betting Parameters\n",
    "BET_THRESHOLD = 0.5\n",
    "WIN_PAYOUT = 0.909\n",
    "LOSS_AMOUNT = 1\n",
    "# EWMA Parameters\n",
    "EWMA_SPAN = 5\n",
    "min_periods_for_ewma = max(1, EWMA_SPAN // 2)\n",
    "# Train / Test Split Years\n",
    "TRAIN_END_SEASON = 2020\n",
    "VALIDATION_END_SEASON = 2022\n",
    "TEST_START_SEASON = VALIDATION_END_SEASON + 1\n",
    "# XG Boost Params\n",
    "# Define XGBoost parameters (use reasonable defaults or slightly tuned values)\n",
    "# We are NOT tuning hyperparameters here, just evaluating feature sets\n",
    "XGB_PARAMS = {\n",
    "    'objective': 'reg:squarederror', # Regression task\n",
    "    'eval_metric': 'rmse',           # Evaluation metric for XGBoost internal use\n",
    "    'eta': 0.1,                      # Learning rate\n",
    "    'max_depth': 5,                  # Max tree depth (control complexity)\n",
    "    'subsample': 0.8,                # Fraction of samples used per tree\n",
    "    'colsample_bytree': 0.8,         # Fraction of features used per tree\n",
    "    'seed': 42,\n",
    "    'nthread': -1, # Use all available CPU threads\n",
    "    'device': 'cuda'\n",
    "    # Enable internal NaN handling if using non-imputed data:\n",
    "    # 'missing': np.nan # Tells XGBoost to handle NaNs\n",
    "}\n",
    "NUM_BOOST_ROUNDS = 100 # Number of boosting rounds (trees)\n",
    "\n",
    "# Val Required Cols\n",
    "VAL_REQUIRED_COLS = ['avg_opening_spread', 'home_points', 'away_points', 'neutral_site', 'id', 'season', 'week', 'home_team', 'away_team', 'home_pregame_elo_calc', 'away_pregame_elo_calc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a824d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN IF USING GOOGLE COLAB\n",
    "MF.mount_with_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7aab1",
   "metadata": {},
   "source": [
    "## Phase 1: Data Foundation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03518c51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load and Pre-Process Games Data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m games_df \u001b[38;5;241m=\u001b[39m \u001b[43mMF\u001b[49m\u001b[38;5;241m.\u001b[39mpreprocess_games_data(MF\u001b[38;5;241m.\u001b[39mload_games_data(DB_PATH))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Add in Returning Production Data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m rp_df \u001b[38;5;241m=\u001b[39m MF\u001b[38;5;241m.\u001b[39mpreprocess_returning_prod_data(MF\u001b[38;5;241m.\u001b[39mload_returning_prod_data(DB_PATH, RP_METRICS_TO_USE))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MF' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and Pre-Process Games Data\n",
    "games_df = MF.preprocess_games_data(MF.load_games_data(DB_PATH))\n",
    "# Add in Returning Production Data\n",
    "rp_df = MF.preprocess_returning_prod_data(MF.load_returning_prod_data(DB_PATH, RP_METRICS_TO_USE))\n",
    "# Load Pre-Calculated ELO Ratings\n",
    "pre_game_elo_df = MF.load_ELO_ratings(PRE_GAME_ELO_CSV_PATH)\n",
    "# Merge Games and ELO Data\n",
    "master_df = MF.merge_elo_to_games(games_df, pre_game_elo_df)\n",
    "# Merge Returning Production to Games\n",
    "master_df = MF.merge_returning_production_to_games(master_df, rp_df, RP_METRICS_TO_USE, DEFAULT_RP_VALUE)\n",
    "# Add Opponent Adjustments to the Master DF\n",
    "master_df = MF.add_opponent_adjustments(master_df)\n",
    "# Drop Missing Targets and Sort Chronologically\n",
    "master_df = MF.drop_missing_target_sort_chronologically(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ece5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Consolidated Data\n",
    "print(\"\\n--- Master DataFrame Info (Now includes all stats) ---\")\n",
    "master_df.info() # Will show many more columns now\n",
    "\n",
    "# Displaying head/tail might be too wide, focus on key columns\n",
    "print(\"\\n--- Master DataFrame Head (Key Columns) ---\")\n",
    "print(master_df[['id', 'season', 'week', 'home_team', 'away_team',\n",
    "                 'avg_closing_spread', 'avg_opening_spread',\n",
    "                 'home_pregame_elo_calc', 'away_pregame_elo_calc']].head())\n",
    "\n",
    "print(\"\\n--- Master DataFrame Tail (Check Sorting - Key Columns) ---\")\n",
    "print(master_df[['id', 'season', 'week', 'home_team', 'away_team',\n",
    "                 'avg_closing_spread', 'avg_opening_spread',\n",
    "                 'home_pregame_elo_calc', 'away_pregame_elo_calc']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Target Variable and Basic Features\n",
    "target_variable, basic_features, master_df = MF.define_target_variable_basic_features(master_df)\n",
    "# Identify Stats to Roll\n",
    "stats_to_roll = MF.identify_stats_to_roll(EWMA_SPAN)\n",
    "# Reshape data to team-centric format\n",
    "team_game_df = MF.reshape_to_team_centric(master_df, stats_to_roll)\n",
    "# Calculate Lagged EWMAs\n",
    "team_game_df, ewma_cols_generated = MF.calculate_lagged_ewma(team_game_df, stats_to_roll, EWMA_SPAN, min_periods_for_ewma)\n",
    "# Merge Back to Master DF\n",
    "master_df = MF.merge_ewma_to_master_df(master_df, team_game_df, ewma_cols_generated)\n",
    "# Create Matchup Features\n",
    "master_df = MF.create_matchup_features(master_df, stats_to_roll)\n",
    "# Create Returning Production Features\n",
    "master_df, potential_features, basic_features = MF.create_returning_prod_features(master_df, RP_METRICS_TO_USE, RP_ACTIVE_WEEKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e43cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and Quantify Missing Data in Features\n",
    "# Use the 'potential_features' list created at the end of Step 3\n",
    "# If you didn't create it, define it again:\n",
    "# all_engineered_features = [col for col in master_df.columns if '_ewma_lag1' in col or 'matchup_' in col]\n",
    "# potential_features = basic_features + all_engineered_features # basic_features defined in step 2\n",
    "\n",
    "# Calculate missing percentage for features we might use\n",
    "print(f\"Checking missing values for {len(potential_features)} potential features...\")\n",
    "missing_summary = master_df[potential_features].isnull().mean().sort_values(ascending=False) * 100\n",
    "missing_summary = missing_summary[missing_summary > 0] # Filter to only show columns with missing data\n",
    "\n",
    "print(\"\\nFeatures with Missing Values (%):\")\n",
    "if missing_summary.empty:\n",
    "    print(\"No missing values found in the potential feature set.\")\n",
    "else:\n",
    "    with pd.option_context('display.max_rows', None): # Ensure all rows are printed\n",
    "        print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop FCS Games\n",
    "master_df = MF.drop_fcs_games(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943335f8",
   "metadata": {},
   "source": [
    "## Phase 2: Feature Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pepare Data and do Temporal Split\n",
    "y_train, X_train, y_val, X_val, X_train_analysis, X_val_analysis, val_df, train_df = MF.temporal_split(TRAIN_END_SEASON, VALIDATION_END_SEASON, master_df, target_variable, potential_features)\n",
    "# Do Initial Filtering\n",
    "current_features = MF.perform_initial_filtering(X_train_analysis, X_train, train_df)\n",
    "# Perform the Correlation Analysis\n",
    "features_to_consider_dropping_corr, correlations_abs = MF.perform_target_correlation_analysis(X_train_analysis, y_train, current_features, target_variable)\n",
    "# Perform Model Based Importance Analysis\n",
    "features_after_initial_analysis, feature_importance_df = MF.perform_model_based_importance(X_train, X_train_analysis, y_train, current_features)\n",
    "# Define Candidate Feature Sets\n",
    "candidate_feature_sets = MF.define_candidate_feature_sets(basic_features, features_after_initial_analysis, features_to_consider_dropping_corr, feature_importance_df, correlations_abs)\n",
    "# Run Feature Set Evaluation\n",
    "all_results = MF.run_feature_set_evaluation(candidate_feature_sets, XGB_PARAMS, NUM_BOOST_ROUNDS, X_train, y_train, X_val, y_val, val_df)\n",
    "# Present Feature Set Evaluation Results\n",
    "results_df = MF.present_feature_set_evaluation_results(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03414e78",
   "metadata": {},
   "source": [
    "## Phase 3: Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28767c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Best Feature SEt\n",
    "best_features = MF.select_best_feature_set(results_df, candidate_feature_sets, X_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna Study - LONG RUNNING CELL\n",
    "study_hp = MF.run_optuna_study(X_train, X_val, y_train, y_val, val_df, best_features, WIN_PAYOUT, LOSS_AMOUNT, BET_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Best Hyperparameters\n",
    "best_xgb_params = MF.identify_best_hyperparameters(study_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d846d",
   "metadata": {},
   "source": [
    "## Phase 4: Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Train, Validation, and Test sets\n",
    "train_val_df, test_df = MF.define_train_val_test_sets(master_df, VALIDATION_END_SEASON, TEST_START_SEASON)\n",
    "# Prepare Data for Final Model\n",
    "X_train_val_nan, y_train_val, X_test_nan, y_test, dtrain_val, dtest = MF.prepare_data_for_final_model(train_val_df, test_df, best_features, target_variable)\n",
    "# Train Final XGBoost Model\n",
    "final_model = MF.train_final_model(best_xgb_params, best_features, dtrain_val, dtest)\n",
    "# Predict on the Test SEt\n",
    "predictions_test_series, y_pred_test = MF.predict_test_set(final_model, dtest, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Statistical Metrics on Test Set\n",
    "MF.evaluate_model_statistics(y_test, y_pred_test, predictions_test_series, test_df, VAL_REQUIRED_COLS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
